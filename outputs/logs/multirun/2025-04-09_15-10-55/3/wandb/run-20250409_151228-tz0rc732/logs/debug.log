2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/3/wandb/run-20250409_151228-tz0rc732/logs/debug.log
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/3/wandb/run-20250409_151228-tz0rc732/logs/debug-internal.log
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 32, 'num_layers': 2, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:12:28,959 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:12:28,962 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:12:28,962 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:12:28,966 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:12:28,969 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:12:29,097 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
2025-04-09 15:12:29,118 ERROR   MainThread:3609697 [wandb_init.py:init():1188] It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
2025-04-09 15:12:29,402 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:12:29,402 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/4/wandb/run-20250409_151229-4zrqekve/logs/debug.log
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/4/wandb/run-20250409_151229-4zrqekve/logs/debug-internal.log
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 64, 'num_layers': 1, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:12:29,403 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:12:29,405 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:12:29,406 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:12:29,409 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:12:29,412 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:13:59,429 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:13:59,449 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/5/wandb/run-20250409_151359-bjxwjxc2/logs/debug.log
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/5/wandb/run-20250409_151359-bjxwjxc2/logs/debug-internal.log
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:13:59,744 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 64, 'num_layers': 1, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:13:59,745 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:13:59,745 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:13:59,747 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:13:59,747 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:13:59,751 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:13:59,754 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:15:29,772 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:15:29,791 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:15:30,079 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:15:30,079 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:15:30,079 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:15:30,079 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:15:30,079 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/6/wandb/run-20250409_151530-wgoxexas/logs/debug.log
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/6/wandb/run-20250409_151530-wgoxexas/logs/debug-internal.log
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:15:30,080 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:15:30,083 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:15:30,083 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:15:30,088 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:15:30,091 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:15:30,253 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
2025-04-09 15:15:30,275 ERROR   MainThread:3609697 [wandb_init.py:init():1188] It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/7/wandb/run-20250409_151530-js4opccz/logs/debug.log
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/7/wandb/run-20250409_151530-js4opccz/logs/debug-internal.log
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:15:30,574 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:15:30,575 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:15:30,575 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:15:30,577 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:15:30,577 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:15:30,581 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:15:30,584 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:17:00,601 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:17:00,621 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/8/wandb/run-20250409_151700-n3nf919e/logs/debug.log
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/8/wandb/run-20250409_151700-n3nf919e/logs/debug-internal.log
2025-04-09 15:17:00,922 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:17:00,923 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 128, 'num_layers': 1, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:17:00,923 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:17:00,923 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:17:00,925 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:17:00,925 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:17:00,929 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:17:00,932 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:18:30,949 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:18:30,968 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:18:31,253 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:18:31,253 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:18:31,253 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:18:31,253 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:18:31,253 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/9/wandb/run-20250409_151831-k183sgc8/logs/debug.log
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/9/wandb/run-20250409_151831-k183sgc8/logs/debug-internal.log
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 128, 'num_layers': 1, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:18:31,254 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:18:31,256 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:18:31,257 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:18:31,261 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:18:31,264 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:20:01,282 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:20:01,302 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:20:01,592 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:20:01,592 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:20:01,592 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/10/wandb/run-20250409_152001-81vckhi5/logs/debug.log
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/10/wandb/run-20250409_152001-81vckhi5/logs/debug-internal.log
2025-04-09 15:20:01,593 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:20:01,594 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 128, 'num_layers': 2, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:20:01,594 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:20:01,594 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:20:01,596 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:20:01,596 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:20:01,600 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:20:01,603 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:21:31,620 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:21:31,640 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Configure stats pid to 3609697
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/.config/wandb/settings
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/0/wandb/settings
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-04-09 15:21:31,926 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program_abspath': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py', 'program': '/home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/scripts/train.py'}
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:_log_setup():528] Logging user logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/11/wandb/run-20250409_152131-nawl2vsh/logs/debug.log
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:_log_setup():529] Logging internal logs to /home/ghazal/Documents/NS_Projects/NS_Revised_P1/neural_decoding/outputs/logs/multirun/2025-04-09_15-10-55/11/wandb/run-20250409_152131-nawl2vsh/logs/debug-internal.log
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:init():568] calling init triggers
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'model': {'type': 'lstm', 'input_size': 421, 'hidden_size': 128, 'num_layers': 2, 'num_classes': 3, 'dropout': 0.5, 'task_weights': {'multiclass': 1.0, 'contralateral': 0.5, 'ipsilateral': 0.5}}, 'dataset': {'name': 'neural_data', 'path': '${paths.data_dir}/aligned_data_009.csv', 'sequence_length': 32, 'apply_pca': True, 'n_components': 3, 'normalize': True, 'train_ratio': 0.7, 'val_ratio': 0.15, 'test_ratio': 0.15, 'batch_size': 32}, 'training': {'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'early_stopping_patience': 7, 'gradient_clip_val': 1.0}, 'seed': 42, 'device': 'cuda', 'paths': {'data_dir': '${oc.env:PWD}/data', 'output_dir': '${oc.env:PWD}/outputs', 'checkpoints_dir': '${paths.output_dir}/checkpoints', 'logs_dir': '${paths.output_dir}/logs', 'visualizations_dir': '${paths.output_dir}/visualizations'}, 'wandb': {'project': 'neural-decoding', 'entity': '${oc.env:USER}', 'group': 'experiments', 'mode': 'online'}}
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:init():618] starting backend
2025-04-09 15:21:31,927 INFO    MainThread:3609697 [wandb_init.py:init():622] setting up manager
2025-04-09 15:21:31,929 INFO    MainThread:3609697 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-09 15:21:31,930 INFO    MainThread:3609697 [wandb_init.py:init():628] backend started and connected
2025-04-09 15:21:31,933 INFO    MainThread:3609697 [wandb_init.py:init():720] updated telemetry
2025-04-09 15:21:31,936 INFO    MainThread:3609697 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-04-09 15:23:01,954 ERROR   MainThread:3609697 [wandb_init.py:init():779] encountered error: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:23:01,973 ERROR   MainThread:3609697 [wandb_init.py:init():1188] Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
Traceback (most recent call last):
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1170, in init
    run = wi.init()
  File "/home/ghazal/anaconda3/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
2025-04-09 15:23:14,163 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,163 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
2025-04-09 15:23:14,164 WARNING MsgRouterThr:3609697 [router.py:message_loop():77] message_loop has been closed
